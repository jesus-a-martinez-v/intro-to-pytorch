{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Saving and Loading Models in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import utils\n",
    "import fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "train_set = datasets.FashionMNIST('Fashion_MNIST_data/', download=True, train=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = datasets.FashionMNIST('Fashion_MNIST_data/', download=True, train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7017e690f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAHTCAYAAAB8/vKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADZNJREFUeJzt3T2PnNd5gOEzX8uZpUlRH4WkNE6V2A5gp3ckQZ3zF5P8jsQw4MqFU8SAmyRABDgxEJcSySWXu7M7Myn0B6RzJ1wwc139w/POx/KeUz2L0+k0AIB5y4d+AAB414kpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgDRuv4DX/78pxai8k74/LPPpmdfv3qdzv7Xf/+36dlFOnmMDz/8MM3/+Ec/np797T//Np39/MWLNA/f1a9/8/v0p+ZmCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEOV9ppyX5aJt1/zbX/xievbRo206++nTp9Oz74XZMcb47LO/mZ5dxI2mx9Mxzb+5fjM9+/Tpk3T2zc3t9Ow//vKf0tl3d3fTs4v4d3I6WRP9rnEzBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgsoKN7+WLzz9P82UN2vWb+VVgY4zx9ddfT89eXb1MZ2+3u+nZuM1r7Pfzq8TGGOPmZv59r6vILi8vp2e//OKLdPYvf/Wr6Vkr1M6PmykARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkBknynfy7Nn76f5m5vb6dm41nOsN/Nf9/v7+3T2ixfPp2frbszlsv1mXq8307P12csu1SdPnqSzLzYX07P7u306m3ePmykARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJEVbHwv7733NM2/ePFievZ4bOu8xjhMT9Y1ZmW+rjGry+vK+afRnn2zmV//tgmr48YY45NPPp6e/a8//jGdzbvHzRQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASCyz/QM7Xa76dm613O1WoXZ9nW9vb0NZ88/97fqTtJ5i7bONDkejmk+7SSNL/zTTz+dnrXP9Py4mQJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEFnBdoY++OCD6dlXr16ls9fr+a/cIq7UurvbT8+uVu135yGuIisWi/bsp9P8s282YYXaGOPRdjs9e3PzJp390YcfpXnOi5spAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAZJ/pGbrc7aZn607R1Wo1Pbvbzj/3GG0Xa90JunzAn63LZfvMjsf5h1+v2z7Tq6uX07N1l+rjx4/TPOfFzRQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgMgKtjO03W6nZ588eZrOfv78m+nZ16+v09mPHj2anj2djunsMU5htq1QO53K2WMsw/64/X6fzv7Df/5hevavfvKTdParV6/TPOfFzRQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASCyz/QMbdab6dnVqv3+Kjsib25v0tl/9umn07PX122X6mq1mp49HA7p7LoPdYz5Xa6bzfx3bYwxnj17Nj1b97iu1/575LtzMwWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBILJj6AytN/Mfe11rNcb8/M1NW8G2XM7/djzG1z2/gK2tb3toh8N9mk/rApftfSvv+3LR1t7V7xtvn5spAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAZJ/pGbrYXDzY2dvtbnr28u4unX1/P79bczHafsqi7pBdLOpv5ofbrfnRRx9Ozy7C/toxxigrSbe7+e/5GGNcX1+ned4+N1MAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIr2M7QehM+9riNaxdWU9095Aq2so/r238hzLY3fbmszz7/m/twmH/Px2jr5+rrLmv3dtttOtsKtnePmykARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkBkn+kZOh3nd0Qejod09m43v+fx1aurdPZD7sY8nY5hNh09Dof2ma1Wq/YAwfE4/76tlvG5w0fe99/yrnEzBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgsoKN72W5bL+/9vu76dljWB03xhiLxfyz141aZQ3aQ2/zKu/7er1JZ19fX0/P7ra7dHb5vnB+fFsAIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAi+0zP0P39/fTsarVKZx8Obx7s7NPpGGbbLtXVav536/E4/9xj9B20xXrd/ovZ72/D7D6dvVrPf9/i14V3kJspAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAZJ/pGbq9DTsib9uOyLIXdLFIR4/jcf7svlN0fjfmYtF+8y7iG1dee/3MylrQ+8P83t4xxlhv/PfId+dmCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAZMfQGbp4dDE9u91t09m3+/n1b2V92xhjrNfza9AOh3T0OJ3KGrO4x2y0+fK+L+P6uFNYm7dazX/eY4zx/rP3p2fv7tqqQt49bqYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRfaZn6Jtvnk/PXu526ewXL16m+aKsQ13EvZxjzB9e95kul23+eJyfPxzn97h+Oz+/SHYR97heXGymZ19eXaWzefe4mQJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEFnBdoZOp7YWq1gt53+/lRVq384/3OseYR3Y4TC/hmyM/r61s9t7/vjy8fTs5ePLdHaxWq3SfP3MefvcTAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACL7TM/Qm5ub6dmXV1fp7JdXL6dnLy426eyyU3SMthR0EY7u+0jbP7Bazf83cYoPXz7z//jqq3T2n//wh9Ozq6V9pufGzRQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgGhRVyR9+fOf5gVRnI+//tnPpmd/9Bd/mc6+3e+nZ5fL9rtztZpfyVX/Rhdl/9uIrz0+++Mf/GB69u/+4e/T2ZyXX//m9+kPxc0UACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgWj/0A3BeLneX07OnUVfnzs+fTsd08uFQptvrLrtUxxjjeGyvvVjGXazwtriZAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQWcHGW1XWqC0W7bffIqzzWi4f7nfnqW6eGw+3xqxuUPvm+fP/nQeB/2NupgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJF9pmeo7PU89eWa08pzj9F2ktZ9puXZD4djOnu5bO9b+r4c2/el7kN9KPW7+pB/Z8xxMwWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBILKCjbfqzZs307OHwyGdfX8/P79atZVYd3d307N1Hdf9ffszv7jYTM/WVWT39/dp/qFYoXZ+3EwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAiMQWASEwBIBJTAIjEFAAi+0x5q65evZqeff/Zs3T27f52erbu5dxtd/PD7eix3+/T/Ok4v5tzu92ms//7T39K8/C2uJkCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABBZwXaGTqf5lVrVV199NT37yccfp7MvNpvp2cPhmM5erVfzs6v52THGuLu7a/P7+fnjqb1v//K736V5eFvcTAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUAKLFQ+62BID/D9xMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAIjEFgEhMASASUwCIxBQAov8BB6XuFV6wrycAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70c01afe48>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 233,
       "width": 233
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "utils.show_image(image[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fully_connected_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5...\n",
      "Training Loss: 1.6235986423492432\n",
      "Test Loss: 0.9154163735687353\n",
      "Test Accuracy: 0.6792396306991577\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.9752584481239319\n",
      "Test Loss: 0.7256749298921816\n",
      "Test Accuracy: 0.7054139971733093\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.8301907765865326\n",
      "Test Loss: 0.677095987424729\n",
      "Test Accuracy: 0.7316879034042358\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.74727776825428\n",
      "Test Loss: 0.613529212915214\n",
      "Test Accuracy: 0.7734872698783875\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.7528123140335083\n",
      "Test Loss: 0.5955675179791299\n",
      "Test Accuracy: 0.7789610028266907\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.6439961528778076\n",
      "Test Loss: 0.5613464435954003\n",
      "Test Accuracy: 0.7851313948631287\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.6528783798217773\n",
      "Test Loss: 0.5853956286694594\n",
      "Test Accuracy: 0.7837380766868591\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.652821562886238\n",
      "Test Loss: 0.5326152460969937\n",
      "Test Accuracy: 0.7987658977508545\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.6515187990665435\n",
      "Test Loss: 0.5318190267511235\n",
      "Test Accuracy: 0.8024482727050781\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.6339236629009247\n",
      "Test Loss: 0.5459597469515102\n",
      "Test Accuracy: 0.8028463125228882\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.6149674683809281\n",
      "Test Loss: 0.5459032595916918\n",
      "Test Accuracy: 0.8034434914588928\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.6448727875947953\n",
      "Test Loss: 0.5014979634315345\n",
      "Test Accuracy: 0.8167794346809387\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.5962053626775742\n",
      "Test Loss: 0.5211346753083976\n",
      "Test Accuracy: 0.8055334687232971\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.5940772980451584\n",
      "Test Loss: 0.49439465971129715\n",
      "Test Accuracy: 0.8207603693008423\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.557954535484314\n",
      "Test Loss: 0.4830741521659171\n",
      "Test Accuracy: 0.8258360028266907\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.5618433344364167\n",
      "Test Loss: 0.5105526274556567\n",
      "Test Accuracy: 0.8136942386627197\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.5710420155525208\n",
      "Test Loss: 0.48558471821675636\n",
      "Test Accuracy: 0.8239450454711914\n",
      "Epoch: 1/5...\n",
      "Training Loss: 0.5511404794454574\n",
      "Test Loss: 0.4722443144222733\n",
      "Test Accuracy: 0.8251393437385559\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.535378709435463\n",
      "Test Loss: 0.48412809933826423\n",
      "Test Accuracy: 0.8222531676292419\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5358800995349884\n",
      "Test Loss: 0.4679543402544252\n",
      "Test Accuracy: 0.8277269005775452\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5817105692625045\n",
      "Test Loss: 0.4670074274585505\n",
      "Test Accuracy: 0.8278264403343201\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5221392810344696\n",
      "Test Loss: 0.48186985389062553\n",
      "Test Accuracy: 0.8226512670516968\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5415178030729294\n",
      "Test Loss: 0.48087357895769134\n",
      "Test Accuracy: 0.8198646306991577\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5526099348068237\n",
      "Test Loss: 0.47850165615795526\n",
      "Test Accuracy: 0.8272293210029602\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.4947161376476288\n",
      "Test Loss: 0.4633804716312202\n",
      "Test Accuracy: 0.8288216590881348\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5110589826107025\n",
      "Test Loss: 0.46705691174716707\n",
      "Test Accuracy: 0.8311106562614441\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.549323108792305\n",
      "Test Loss: 0.4683693926425497\n",
      "Test Accuracy: 0.8308120965957642\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5445919495820999\n",
      "Test Loss: 0.4627471962931809\n",
      "Test Accuracy: 0.8269307613372803\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5827776825428009\n",
      "Test Loss: 0.45736788564426883\n",
      "Test Accuracy: 0.8268312215805054\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5633462148904801\n",
      "Test Loss: 0.46420404770571716\n",
      "Test Accuracy: 0.8307125568389893\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.503075566291809\n",
      "Test Loss: 0.45092537714417574\n",
      "Test Accuracy: 0.8382762670516968\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.536830004453659\n",
      "Test Loss: 0.4561189761397186\n",
      "Test Accuracy: 0.8382762670516968\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5059165889024735\n",
      "Test Loss: 0.43768787384033203\n",
      "Test Accuracy: 0.8369824886322021\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5127287185192109\n",
      "Test Loss: 0.46070664001118605\n",
      "Test Accuracy: 0.8327030539512634\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5197846335172653\n",
      "Test Loss: 0.4594292244903601\n",
      "Test Accuracy: 0.8336982727050781\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.5055381345748902\n",
      "Test Loss: 0.43624039981395574\n",
      "Test Accuracy: 0.8421576619148254\n",
      "Epoch: 2/5...\n",
      "Training Loss: 0.487178720831871\n",
      "Test Loss: 0.433477521607071\n",
      "Test Accuracy: 0.8446456789970398\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5061788988113404\n",
      "Test Loss: 0.4344329672634222\n",
      "Test Accuracy: 0.8438495397567749\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5161202704906463\n",
      "Test Loss: 0.44181623020369537\n",
      "Test Accuracy: 0.8354896306991577\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5131933069229127\n",
      "Test Loss: 0.4336983917435263\n",
      "Test Accuracy: 0.8427547812461853\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.525024111866951\n",
      "Test Loss: 0.42970047027442104\n",
      "Test Accuracy: 0.8424562215805054\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.4996780526638031\n",
      "Test Loss: 0.45371802663727173\n",
      "Test Accuracy: 0.8384753465652466\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5169683581590653\n",
      "Test Loss: 0.45670301405487546\n",
      "Test Accuracy: 0.8359872698783875\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.500487979054451\n",
      "Test Loss: 0.436831031445485\n",
      "Test Accuracy: 0.8443471193313599\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.47068789780139925\n",
      "Test Loss: 0.4271209608217713\n",
      "Test Accuracy: 0.8459395170211792\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5205237418413162\n",
      "Test Loss: 0.42953570813510067\n",
      "Test Accuracy: 0.8431528806686401\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5126279020309448\n",
      "Test Loss: 0.44421833203097055\n",
      "Test Accuracy: 0.8403662443161011\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.48616295218467714\n",
      "Test Loss: 0.4276727829958982\n",
      "Test Accuracy: 0.8467356562614441\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.4991515064239502\n",
      "Test Loss: 0.4254649212216116\n",
      "Test Accuracy: 0.8451433181762695\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.47628621876239774\n",
      "Test Loss: 0.43541342143420203\n",
      "Test Accuracy: 0.8388733863830566\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5276345905661582\n",
      "Test Loss: 0.4343415109594916\n",
      "Test Accuracy: 0.8433519005775452\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.4931821945309639\n",
      "Test Loss: 0.41369689668819404\n",
      "Test Accuracy: 0.850119411945343\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.4836471354961395\n",
      "Test Loss: 0.41953678286758955\n",
      "Test Accuracy: 0.8493232727050781\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.5113344371318818\n",
      "Test Loss: 0.43793921258039537\n",
      "Test Accuracy: 0.8442476391792297\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.4840178674459457\n",
      "Test Loss: 0.42440924541965414\n",
      "Test Accuracy: 0.8450437784194946\n",
      "Epoch: 3/5...\n",
      "Training Loss: 0.48354034721851347\n",
      "Test Loss: 0.4165064605178347\n",
      "Test Accuracy: 0.8478304147720337\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.5163952189683915\n",
      "Test Loss: 0.4261216570617287\n",
      "Test Accuracy: 0.8454418778419495\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.47507264733314514\n",
      "Test Loss: 0.4266106013659459\n",
      "Test Accuracy: 0.8451433181762695\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.47806631684303286\n",
      "Test Loss: 0.4177490512656558\n",
      "Test Accuracy: 0.8497213125228882\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.47250494360923767\n",
      "Test Loss: 0.4169208794642406\n",
      "Test Accuracy: 0.8510151505470276\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.47456911444664\n",
      "Test Loss: 0.42453098534398775\n",
      "Test Accuracy: 0.8471337556838989\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.47728938817977906\n",
      "Test Loss: 0.4255025883199303\n",
      "Test Accuracy: 0.8474323153495789\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.45523099720478055\n",
      "Test Loss: 0.4140520260022704\n",
      "Test Accuracy: 0.8491241931915283\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.48550519794225694\n",
      "Test Loss: 0.4101102909274921\n",
      "Test Accuracy: 0.8500199317932129\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.46008994460105895\n",
      "Test Loss: 0.41880272082082787\n",
      "Test Accuracy: 0.8453423380851746\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.47746653378009796\n",
      "Test Loss: 0.41331940376834503\n",
      "Test Accuracy: 0.8526074886322021\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.4746889585256577\n",
      "Test Loss: 0.41379443598780663\n",
      "Test Accuracy: 0.8482285141944885\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.5239810770750046\n",
      "Test Loss: 0.4177198015200864\n",
      "Test Accuracy: 0.8495222926139832\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.471755163371563\n",
      "Test Loss: 0.42255195633620973\n",
      "Test Accuracy: 0.8444466590881348\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.4696107217669487\n",
      "Test Loss: 0.4008684687933345\n",
      "Test Accuracy: 0.8559912443161011\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.457312216758728\n",
      "Test Loss: 0.41530047508941337\n",
      "Test Accuracy: 0.8522093892097473\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.45832707822322843\n",
      "Test Loss: 0.40559757477158953\n",
      "Test Accuracy: 0.8518112897872925\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.4676530355215073\n",
      "Test Loss: 0.41177349115253253\n",
      "Test Accuracy: 0.8496218323707581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5...\n",
      "Training Loss: 0.46924746215343477\n",
      "Test Loss: 0.4222900622589573\n",
      "Test Accuracy: 0.8469347357749939\n",
      "Epoch: 4/5...\n",
      "Training Loss: 0.46350632309913636\n",
      "Test Loss: 0.42874700552339007\n",
      "Test Accuracy: 0.8392714858055115\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.48928523421287534\n",
      "Test Loss: 0.4047617115982019\n",
      "Test Accuracy: 0.8543989062309265\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4382611295580864\n",
      "Test Loss: 0.41814609061760505\n",
      "Test Accuracy: 0.8459395170211792\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4956448757648468\n",
      "Test Loss: 0.4025262423381684\n",
      "Test Accuracy: 0.8558917045593262\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.43382257014513015\n",
      "Test Loss: 0.40935344462561757\n",
      "Test Accuracy: 0.8503184914588928\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.45617676675319674\n",
      "Test Loss: 0.4280296883955123\n",
      "Test Accuracy: 0.8446456789970398\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.45082080334424973\n",
      "Test Loss: 0.40685346589726246\n",
      "Test Accuracy: 0.8458399772644043\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.46354219049215317\n",
      "Test Loss: 0.41227705064852527\n",
      "Test Accuracy: 0.8531050682067871\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4466827529668808\n",
      "Test Loss: 0.41645477493857125\n",
      "Test Accuracy: 0.8508160710334778\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.45595902889966966\n",
      "Test Loss: 0.4116256725826081\n",
      "Test Accuracy: 0.8536027073860168\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4629792582988739\n",
      "Test Loss: 0.40471646797125505\n",
      "Test Accuracy: 0.8514131903648376\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.46712843954563144\n",
      "Test Loss: 0.4036875604444249\n",
      "Test Accuracy: 0.8534036874771118\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.47414076179265974\n",
      "Test Loss: 0.40095486923767504\n",
      "Test Accuracy: 0.8544983863830566\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4639013484120369\n",
      "Test Loss: 0.39906700828652475\n",
      "Test Accuracy: 0.8548964858055115\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4533260864019394\n",
      "Test Loss: 0.4115398444567516\n",
      "Test Accuracy: 0.8514131903648376\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4583144733309746\n",
      "Test Loss: 0.40688570327819534\n",
      "Test Accuracy: 0.8529060482978821\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.4453521341085434\n",
      "Test Loss: 0.39381386681347136\n",
      "Test Accuracy: 0.8585788011550903\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.45345939457416534\n",
      "Test Loss: 0.40533408902253315\n",
      "Test Accuracy: 0.8537022471427917\n",
      "Epoch: 5/5...\n",
      "Training Loss: 0.43887400448322295\n",
      "Test Loss: 0.40226340075587014\n",
      "Test Accuracy: 0.8538017272949219\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model.train(model, train_loader, test_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "\n",
      "The state dict keys:\n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(f'Our model: \\n\\n{model}\\n')\n",
    "print(f'The state dict keys:\\n\\n {model.state_dict().keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d778f1c3d8f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Will fail because the tensor sizes are wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model."
     ]
    }
   ],
   "source": [
    "model = fully_connected_model.Network(784, 10, [400, 200, 100])\n",
    "\n",
    "# Will fail because the tensor sizes are wrong\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint: {\n",
    "        'input_size': 784,\n",
    "        'output_size': 10,\n",
    "        'hidden_layers': [l.out_features for l in model.hidden_layers],\n",
    "        'state_dict': model.state_dict()\n",
    "    }\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model = fully_connected_model.Network(checkpoint['input_size'],\n",
    "                                          checkpoint['output_size'],\n",
    "                                          checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
